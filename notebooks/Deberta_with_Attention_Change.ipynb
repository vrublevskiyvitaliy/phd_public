{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e3bf529114244e00a642db767eacdcc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f761415994a84df5bcbce155329a383b",
              "IPY_MODEL_d83d9326bdf64d0b834916234e4a5de3",
              "IPY_MODEL_ed2ee18a2d4a441f9ce7984cbc09ebff"
            ],
            "layout": "IPY_MODEL_a56e82a22b714468bfc89148c3e2b4e7"
          }
        },
        "f761415994a84df5bcbce155329a383b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4683ed90c3c04287ba4667913c6a664f",
            "placeholder": "​",
            "style": "IPY_MODEL_e6fc4b72706449ffa2c54e68a5b1bd85",
            "value": "Map: 100%"
          }
        },
        "d83d9326bdf64d0b834916234e4a5de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b67f3472c086401588afb34730a9ba25",
            "max": 3668,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94eb9a7153af4295a0378bf6e70e75ca",
            "value": 3668
          }
        },
        "ed2ee18a2d4a441f9ce7984cbc09ebff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2849e8f2841c49a1af964045956b3a70",
            "placeholder": "​",
            "style": "IPY_MODEL_3c9f305cf875429390b6f6f3016e1b1a",
            "value": " 3668/3668 [01:29&lt;00:00, 46.87 examples/s]"
          }
        },
        "a56e82a22b714468bfc89148c3e2b4e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4683ed90c3c04287ba4667913c6a664f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6fc4b72706449ffa2c54e68a5b1bd85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b67f3472c086401588afb34730a9ba25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94eb9a7153af4295a0378bf6e70e75ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2849e8f2841c49a1af964045956b3a70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c9f305cf875429390b6f6f3016e1b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "deda32776a354094ab0f0b5f369dbfc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0599f81a36ac412aa94b466bc6d772ce",
              "IPY_MODEL_a33686dfe72e4d8abafe0101a461c608",
              "IPY_MODEL_0e4e92a860ba4658a07f2dc4bf2575b6"
            ],
            "layout": "IPY_MODEL_690867ed54d0431ab3ef89b587db2353"
          }
        },
        "0599f81a36ac412aa94b466bc6d772ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_529fa1466faf4642a1dbf5a948a2cdf3",
            "placeholder": "​",
            "style": "IPY_MODEL_426c71faf9a244df9965258ca85aaddf",
            "value": "Map: 100%"
          }
        },
        "a33686dfe72e4d8abafe0101a461c608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16599f70c76f4d9ea40d44dae2a989f0",
            "max": 408,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab98eeafa7c14ecbb455bb6680068c1b",
            "value": 408
          }
        },
        "0e4e92a860ba4658a07f2dc4bf2575b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44866e7581314b97821140d8da1a2d3a",
            "placeholder": "​",
            "style": "IPY_MODEL_5548eedb6f534f4b9299dd1d0b76b407",
            "value": " 408/408 [00:10&lt;00:00, 13.79 examples/s]"
          }
        },
        "690867ed54d0431ab3ef89b587db2353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "529fa1466faf4642a1dbf5a948a2cdf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "426c71faf9a244df9965258ca85aaddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16599f70c76f4d9ea40d44dae2a989f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab98eeafa7c14ecbb455bb6680068c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44866e7581314b97821140d8da1a2d3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5548eedb6f534f4b9299dd1d0b76b407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a32648ffa9204b908a959c8bb8341ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd8916407dff47818f80d9d6d1e7dfd3",
              "IPY_MODEL_531affd96b454e0ba5535a97cf13a5a4",
              "IPY_MODEL_2d39afa2ee344846b7c2683f00b67c6e"
            ],
            "layout": "IPY_MODEL_e66ee939064b468382b066f010cb153a"
          }
        },
        "dd8916407dff47818f80d9d6d1e7dfd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_310762e02ce74a3586cc06183c05fbad",
            "placeholder": "​",
            "style": "IPY_MODEL_f799499ebb7b4407819f5599dbb798f7",
            "value": "Map: 100%"
          }
        },
        "531affd96b454e0ba5535a97cf13a5a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5443cad6d6144ce85b3c599914b8f1e",
            "max": 1725,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6159353d1d9b48d0aa6219ecce6bc308",
            "value": 1725
          }
        },
        "2d39afa2ee344846b7c2683f00b67c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1eee788f28da45fa8ed2c9516bc2f95a",
            "placeholder": "​",
            "style": "IPY_MODEL_887e519bc2744ad4a837de29504c27cd",
            "value": " 1725/1725 [00:41&lt;00:00, 48.07 examples/s]"
          }
        },
        "e66ee939064b468382b066f010cb153a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "310762e02ce74a3586cc06183c05fbad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f799499ebb7b4407819f5599dbb798f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5443cad6d6144ce85b3c599914b8f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6159353d1d9b48d0aa6219ecce6bc308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1eee788f28da45fa8ed2c9516bc2f95a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "887e519bc2744ad4a837de29504c27cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57f2783ce67642bda5534cd8de9363ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5f8238319b54d9b9cd54c6024700386",
              "IPY_MODEL_c229efd7f6df45c5941a3d3a86dac224",
              "IPY_MODEL_bd60c6cb064e4dd3b8d10c2ec912f84f"
            ],
            "layout": "IPY_MODEL_f8c550d9175c4b33bc8898080b8ce665"
          }
        },
        "a5f8238319b54d9b9cd54c6024700386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dbf4cf75ac94664a1494fd42122607c",
            "placeholder": "​",
            "style": "IPY_MODEL_36e3bfe1a83c43ffb7671383ff44c4cb",
            "value": "100%"
          }
        },
        "c229efd7f6df45c5941a3d3a86dac224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9af8cb66c6c2490ea5cc947eff9f3d04",
            "max": 4590,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be02eba9b71c440e94b23f8329370d2a",
            "value": 4590
          }
        },
        "bd60c6cb064e4dd3b8d10c2ec912f84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc7b800aa5614864a236df1f510c6bff",
            "placeholder": "​",
            "style": "IPY_MODEL_1ccb3a623fd247ac9a7d5cd3698dc8ed",
            "value": " 4590/4590 [1:23:43&lt;00:00,  1.88it/s]"
          }
        },
        "f8c550d9175c4b33bc8898080b8ce665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dbf4cf75ac94664a1494fd42122607c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36e3bfe1a83c43ffb7671383ff44c4cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9af8cb66c6c2490ea5cc947eff9f3d04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be02eba9b71c440e94b23f8329370d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc7b800aa5614864a236df1f510c6bff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ccb3a623fd247ac9a7d5cd3698dc8ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install datasets transformers==4.28.0 evaluate"
      ],
      "metadata": {
        "id": "-TH4wY5rdS3k"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!python -m spacy download en_core_web_md"
      ],
      "metadata": {
        "id": "haHsUHAjC__h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!rm -rf phd_public\n",
        "!git clone https://github.com/vrublevskiyvitaliy/phd_public.git"
      ],
      "metadata": {
        "id": "qCzAxB3ifdUR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import evaluate\n",
        "\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding, get_scheduler, AutoConfig\n",
        "from transformers.utils import PaddingStrategy\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers.tokenization_utils_base import TruncationStrategy\n",
        "\n",
        "from datasets import load_dataset, load_metric\n",
        "from functools import partial\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from torch.optim import AdamW\n"
      ],
      "metadata": {
        "id": "OYVqKwxwexpt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from phd_public.models.enriched_tokeniser import preprocess_dataset_final\n",
        "# from phd_public.models.deberta_model_attention_change import DebertaForSequenceClassificationV2\n",
        "from phd_public.utils.seed import init_seed\n",
        "# from phd_public.models.deberta_model_classic import DebertaForSequenceClassificationClassic\n",
        "# from phd_public.models.bert_tokeniser_with_pos_tags import preprocess_dataset_with_pos_tags\n",
        "\n"
      ],
      "metadata": {
        "id": "Hyq8f_sHfeCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c3a6a7c-07e0-4815-fcd1-98a596cdadec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GLOBALS\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "MAX_LEN = 256\n",
        "BATCH_SIZE = 8\n",
        "TRUNCATION = TruncationStrategy.LONGEST_FIRST\n",
        "PADDING=PaddingStrategy.MAX_LENGTH\n",
        "SEED = 42\n",
        "LR = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 10\n",
        "# DATASET_PART = \"[:10%]\"\n",
        "DATASET_PART = \"\"\n",
        "\n",
        "\n",
        "model_name = \"microsoft/deberta-base\""
      ],
      "metadata": {
        "id": "daAHfOu2enGO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_seed(SEED)"
      ],
      "metadata": {
        "id": "7YRT0-98FMYK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "assert(transformers.__version__ == '4.28.0')\n",
        "\n",
        "from torch import nn\n",
        "from transformers.models.deberta.modeling_deberta import (\n",
        "    DebertaLayerNorm,\n",
        "    DebertaPreTrainedModel,\n",
        "    StableDropout,\n",
        "    DebertaEncoder,\n",
        "    ContextPooler,\n",
        "    DisentangledSelfAttention,\n",
        "    DebertaModel,\n",
        "    DebertaForSequenceClassification,\n",
        "    DebertaIntermediate,\n",
        "    XSoftmax,\n",
        "    DebertaOutput,\n",
        "    DebertaEmbeddings,\n",
        "    DebertaSelfOutput,\n",
        "    build_relative_position\n",
        ")\n",
        "from typing import List, Optional, Tuple, Union\n",
        "from transformers.modeling_outputs import BaseModelOutput, SequenceClassifierOutput\n",
        "from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss, MSELoss\n",
        "\n",
        "from collections.abc import Sequence\n",
        "\n",
        "class DisentangledSelfAttentionV2(DisentangledSelfAttention):\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        attention_mask,\n",
        "        output_attentions=False,\n",
        "        query_states=None,\n",
        "        relative_pos=None,\n",
        "        rel_embeddings=None,\n",
        "        attention_enhencer=None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Call the module\n",
        "\n",
        "        Args:\n",
        "            hidden_states (`torch.FloatTensor`):\n",
        "                Input states to the module usually the output from previous layer, it will be the Q,K and V in\n",
        "                *Attention(Q,K,V)*\n",
        "\n",
        "            attention_mask (`torch.ByteTensor`):\n",
        "                An attention mask matrix of shape [*B*, *N*, *N*] where *B* is the batch size, *N* is the maximum\n",
        "                sequence length in which element [i,j] = *1* means the *i* th token in the input can attend to the *j*\n",
        "                th token.\n",
        "\n",
        "            output_attentions (`bool`, optional):\n",
        "                Whether return the attention matrix.\n",
        "\n",
        "            query_states (`torch.FloatTensor`, optional):\n",
        "                The *Q* state in *Attention(Q,K,V)*.\n",
        "\n",
        "            relative_pos (`torch.LongTensor`):\n",
        "                The relative position encoding between the tokens in the sequence. It's of shape [*B*, *N*, *N*] with\n",
        "                values ranging in [*-max_relative_positions*, *max_relative_positions*].\n",
        "\n",
        "            rel_embeddings (`torch.FloatTensor`):\n",
        "                The embedding of relative distances. It's a tensor of shape [\\\\(2 \\\\times\n",
        "                \\\\text{max_relative_positions}\\\\), *hidden_size*].\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        if query_states is None:\n",
        "            qp = self.in_proj(hidden_states)  # .split(self.all_head_size, dim=-1)\n",
        "            query_layer, key_layer, value_layer = self.transpose_for_scores(qp).chunk(3, dim=-1)\n",
        "        else:\n",
        "\n",
        "            def linear(w, b, x):\n",
        "                if b is not None:\n",
        "                    return torch.matmul(x, w.t()) + b.t()\n",
        "                else:\n",
        "                    return torch.matmul(x, w.t())  # + b.t()\n",
        "\n",
        "            ws = self.in_proj.weight.chunk(self.num_attention_heads * 3, dim=0)\n",
        "            qkvw = [torch.cat([ws[i * 3 + k] for i in range(self.num_attention_heads)], dim=0) for k in range(3)]\n",
        "            qkvb = [None] * 3\n",
        "\n",
        "            q = linear(qkvw[0], qkvb[0], query_states.to(dtype=qkvw[0].dtype))\n",
        "            k, v = [linear(qkvw[i], qkvb[i], hidden_states.to(dtype=qkvw[i].dtype)) for i in range(1, 3)]\n",
        "            query_layer, key_layer, value_layer = [self.transpose_for_scores(x) for x in [q, k, v]]\n",
        "\n",
        "        query_layer = query_layer + self.transpose_for_scores(self.q_bias[None, None, :])\n",
        "        value_layer = value_layer + self.transpose_for_scores(self.v_bias[None, None, :])\n",
        "\n",
        "        rel_att = None\n",
        "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
        "        scale_factor = 1 + len(self.pos_att_type)\n",
        "        scale = torch.sqrt(torch.tensor(query_layer.size(-1), dtype=torch.float) * scale_factor)\n",
        "        query_layer = query_layer / scale.to(dtype=query_layer.dtype)\n",
        "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
        "        if self.relative_attention:\n",
        "            rel_embeddings = self.pos_dropout(rel_embeddings)\n",
        "            rel_att = self.disentangled_att_bias(query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\n",
        "\n",
        "        if rel_att is not None:\n",
        "            attention_scores = attention_scores + rel_att\n",
        "\n",
        "        ## APPLY HERE MODIFICATION VITALII TODO\n",
        "\n",
        "        # bxhxlxd\n",
        "        if self.talking_head:\n",
        "            attention_scores = self.head_logits_proj(attention_scores.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "\n",
        "        # attention_scores = Number of Batches x Num of heads x Max Length x Max Length\n",
        "        # attention_enhencer = Number of Batches x Num of heads x Max Length x Max Length\n",
        "        # attention_scores_ = attention_scores\n",
        "        attention_scores = torch.mul(attention_scores, attention_enhencer)\n",
        "        # if not torch.equal(attention_scores_v2, attention_scores_):\n",
        "        #   print(\"Change in scores!\")\n",
        "        # else:\n",
        "        #   print(\"Scores are the same!\")\n",
        "        attention_probs = XSoftmax.apply(attention_scores, attention_mask, -1)\n",
        "\n",
        "        # attention_probs = Number of Batches x Num of heads x Max Length x Max Length\n",
        "        attention_probs = self.dropout(attention_probs)\n",
        "        if self.talking_head:\n",
        "            attention_probs = self.head_weights_proj(attention_probs.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "\n",
        "        context_layer = torch.matmul(attention_probs, value_layer)\n",
        "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
        "        new_context_layer_shape = context_layer.size()[:-2] + (-1,)\n",
        "        context_layer = context_layer.view(new_context_layer_shape)\n",
        "        if output_attentions:\n",
        "            return (context_layer, attention_probs)\n",
        "        else:\n",
        "            return context_layer\n",
        "\n",
        "\n",
        "class DebertaAttentionV2(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.self = DisentangledSelfAttentionV2(config)\n",
        "        self.output = DebertaSelfOutput(config)\n",
        "        self.config = config\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        attention_mask,\n",
        "        attention_enhencer,\n",
        "        output_attentions=False,\n",
        "        query_states=None,\n",
        "        relative_pos=None,\n",
        "        rel_embeddings=None,\n",
        "    ):\n",
        "        self_output = self.self(\n",
        "            hidden_states,\n",
        "            attention_mask,\n",
        "            output_attentions,\n",
        "            query_states=query_states,\n",
        "            relative_pos=relative_pos,\n",
        "            rel_embeddings=rel_embeddings,\n",
        "            attention_enhencer=attention_enhencer,\n",
        "        )\n",
        "        if output_attentions:\n",
        "            self_output, att_matrix = self_output\n",
        "        if query_states is None:\n",
        "            query_states = hidden_states\n",
        "        attention_output = self.output(self_output, query_states)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (attention_output, att_matrix)\n",
        "        else:\n",
        "            return attention_output\n",
        "\n",
        "class DebertaLayerV2(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.attention = DebertaAttentionV2(config)\n",
        "        self.intermediate = DebertaIntermediate(config)\n",
        "        self.output = DebertaOutput(config)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        attention_mask,\n",
        "        attention_enhencer,\n",
        "        query_states=None,\n",
        "        relative_pos=None,\n",
        "        rel_embeddings=None,\n",
        "        output_attentions=False,\n",
        "    ):\n",
        "        attention_output = self.attention(\n",
        "            hidden_states,\n",
        "            attention_mask,\n",
        "            output_attentions=output_attentions,\n",
        "            query_states=query_states,\n",
        "            relative_pos=relative_pos,\n",
        "            rel_embeddings=rel_embeddings,\n",
        "            attention_enhencer=attention_enhencer,\n",
        "        )\n",
        "        if output_attentions:\n",
        "            attention_output, att_matrix = attention_output\n",
        "        intermediate_output = self.intermediate(attention_output)\n",
        "        layer_output = self.output(intermediate_output, attention_output)\n",
        "        if output_attentions:\n",
        "            return (layer_output, att_matrix)\n",
        "        else:\n",
        "            return layer_output\n",
        "\n",
        "\n",
        "class DebertaEncoderV2(nn.Module):\n",
        "    \"\"\"Modified BertEncoder with relative position bias support\"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.layer = nn.ModuleList([DebertaLayerV2(config) for _ in range(config.num_hidden_layers)])\n",
        "        self.relative_attention = getattr(config, \"relative_attention\", False)\n",
        "        if self.relative_attention:\n",
        "            self.max_relative_positions = getattr(config, \"max_relative_positions\", -1)\n",
        "            if self.max_relative_positions < 1:\n",
        "                self.max_relative_positions = config.max_position_embeddings\n",
        "            self.rel_embeddings = nn.Embedding(self.max_relative_positions * 2, config.hidden_size)\n",
        "        self.gradient_checkpointing = False\n",
        "\n",
        "    def get_rel_embedding(self):\n",
        "        rel_embeddings = self.rel_embeddings.weight if self.relative_attention else None\n",
        "        return rel_embeddings\n",
        "\n",
        "    def get_attention_mask(self, attention_mask):\n",
        "        if attention_mask.dim() <= 2:\n",
        "            extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "            attention_mask = extended_attention_mask * extended_attention_mask.squeeze(-2).unsqueeze(-1)\n",
        "            attention_mask = attention_mask.byte()\n",
        "        elif attention_mask.dim() == 3:\n",
        "            attention_mask = attention_mask.unsqueeze(1)\n",
        "\n",
        "        return attention_mask\n",
        "\n",
        "    def get_rel_pos(self, hidden_states, query_states=None, relative_pos=None):\n",
        "        if self.relative_attention and relative_pos is None:\n",
        "            q = query_states.size(-2) if query_states is not None else hidden_states.size(-2)\n",
        "            relative_pos = build_relative_position(q, hidden_states.size(-2), hidden_states.device)\n",
        "        return relative_pos\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states,\n",
        "        attention_mask,\n",
        "        attention_enhencer,\n",
        "        output_hidden_states=True,\n",
        "        output_attentions=False,\n",
        "        query_states=None,\n",
        "        relative_pos=None,\n",
        "        return_dict=True,\n",
        "    ):\n",
        "        attention_mask = self.get_attention_mask(attention_mask)\n",
        "        relative_pos = self.get_rel_pos(hidden_states, query_states, relative_pos)\n",
        "\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_attentions = () if output_attentions else None\n",
        "\n",
        "        if isinstance(hidden_states, Sequence):\n",
        "            next_kv = hidden_states[0]\n",
        "        else:\n",
        "            next_kv = hidden_states\n",
        "        rel_embeddings = self.get_rel_embedding()\n",
        "        for i, layer_module in enumerate(self.layer):\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "            if self.gradient_checkpointing and self.training:\n",
        "\n",
        "                def create_custom_forward(module):\n",
        "                    def custom_forward(*inputs):\n",
        "                        return module(*inputs, output_attentions)\n",
        "\n",
        "                    return custom_forward\n",
        "                hidden_states = torch.utils.checkpoint.checkpoint(\n",
        "                    create_custom_forward(layer_module),\n",
        "                    next_kv,\n",
        "                    attention_mask,\n",
        "                    query_states,\n",
        "                    relative_pos,\n",
        "                    rel_embeddings,\n",
        "                )\n",
        "            else:\n",
        "                hidden_states = layer_module(\n",
        "                    next_kv,\n",
        "                    attention_mask,\n",
        "                    attention_enhencer=attention_enhencer,\n",
        "                    query_states=query_states,\n",
        "                    relative_pos=relative_pos,\n",
        "                    rel_embeddings=rel_embeddings,\n",
        "                    output_attentions=output_attentions,\n",
        "                )\n",
        "\n",
        "            if output_attentions:\n",
        "                hidden_states, att_m = hidden_states\n",
        "\n",
        "            if query_states is not None:\n",
        "                query_states = hidden_states\n",
        "                if isinstance(hidden_states, Sequence):\n",
        "                    next_kv = hidden_states[i + 1] if i + 1 < len(self.layer) else None\n",
        "            else:\n",
        "                next_kv = hidden_states\n",
        "\n",
        "            if output_attentions:\n",
        "                all_attentions = all_attentions + (att_m,)\n",
        "\n",
        "        if output_hidden_states:\n",
        "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "        if not return_dict:\n",
        "            return tuple(v for v in [hidden_states, all_hidden_states, all_attentions] if v is not None)\n",
        "        return BaseModelOutput(\n",
        "            last_hidden_state=hidden_states, hidden_states=all_hidden_states, attentions=all_attentions\n",
        "        )\n",
        "\n",
        "class DebertaModelV2(DebertaModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.embeddings = DebertaEmbeddings(config)\n",
        "        self.encoder = DebertaEncoderV2(config)\n",
        "        self.z_steps = 0\n",
        "        self.config = config\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        attention_enhencer: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, BaseModelOutput]:\n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        )\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
        "        elif input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "        elif inputs_embeds is not None:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "        else:\n",
        "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
        "\n",
        "        device = input_ids.device if input_ids is not None else inputs_embeds.device\n",
        "\n",
        "        if attention_mask is None:\n",
        "            attention_mask = torch.ones(input_shape, device=device)\n",
        "        if token_type_ids is None:\n",
        "            token_type_ids = torch.zeros(input_shape, dtype=torch.long, device=device)\n",
        "\n",
        "        embedding_output = self.embeddings(\n",
        "            input_ids=input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            mask=attention_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "        )\n",
        "\n",
        "        encoder_outputs = self.encoder(\n",
        "            embedding_output,\n",
        "            attention_mask,\n",
        "            output_hidden_states=True,\n",
        "            output_attentions=output_attentions,\n",
        "            return_dict=return_dict,\n",
        "            attention_enhencer=attention_enhencer,\n",
        "        )\n",
        "        encoded_layers = encoder_outputs[1]\n",
        "\n",
        "        if self.z_steps > 1:\n",
        "            hidden_states = encoded_layers[-2]\n",
        "            layers = [self.encoder.layer[-1] for _ in range(self.z_steps)]\n",
        "            query_states = encoded_layers[-1]\n",
        "            rel_embeddings = self.encoder.get_rel_embedding()\n",
        "            attention_mask = self.encoder.get_attention_mask(attention_mask)\n",
        "            rel_pos = self.encoder.get_rel_pos(embedding_output)\n",
        "            for layer in layers[1:]:\n",
        "                query_states = layer(\n",
        "                    hidden_states,\n",
        "                    attention_mask,\n",
        "                    output_attentions=False,\n",
        "                    query_states=query_states,\n",
        "                    relative_pos=rel_pos,\n",
        "                    rel_embeddings=rel_embeddings,\n",
        "                    attention_enhencer=attention_enhencer,\n",
        "                )\n",
        "                encoded_layers.append(query_states)\n",
        "\n",
        "        sequence_output = encoded_layers[-1]\n",
        "\n",
        "        if not return_dict:\n",
        "            return (sequence_output,) + encoder_outputs[(1 if output_hidden_states else 2) :]\n",
        "\n",
        "        return BaseModelOutput(\n",
        "            last_hidden_state=sequence_output,\n",
        "            hidden_states=encoder_outputs.hidden_states if output_hidden_states else None,\n",
        "            attentions=encoder_outputs.attentions,\n",
        "        )\n",
        "\n",
        "class DebertaForSequenceClassificationV2(DebertaForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        num_labels = getattr(config, \"num_labels\", 2)\n",
        "        self.num_labels = num_labels\n",
        "\n",
        "        self.deberta = DebertaModelV2(config)\n",
        "        self.pooler = ContextPooler(config)\n",
        "        output_dim = self.pooler.output_dim\n",
        "\n",
        "        self.classifier = nn.Linear(output_dim, num_labels)\n",
        "        drop_out = getattr(config, \"cls_dropout\", None)\n",
        "        drop_out = self.config.hidden_dropout_prob if drop_out is None else drop_out\n",
        "        self.dropout = StableDropout(drop_out)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        attention_enhencer: Optional[torch.Tensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        labels: Optional[torch.Tensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple, SequenceClassifierOutput]:\n",
        "        r\"\"\"\n",
        "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
        "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
        "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
        "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        outputs = self.deberta(\n",
        "            input_ids,\n",
        "            token_type_ids=token_type_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            attention_enhencer=attention_enhencer,\n",
        "            position_ids=position_ids,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        encoder_layer = outputs[0]\n",
        "        pooled_output = self.pooler(encoder_layer)\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.config.problem_type is None:\n",
        "                if self.num_labels == 1:\n",
        "                    # regression task\n",
        "                    loss_fn = nn.MSELoss()\n",
        "                    logits = logits.view(-1).to(labels.dtype)\n",
        "                    loss = loss_fn(logits, labels.view(-1))\n",
        "                elif labels.dim() == 1 or labels.size(-1) == 1:\n",
        "                    label_index = (labels >= 0).nonzero()\n",
        "                    labels = labels.long()\n",
        "                    if label_index.size(0) > 0:\n",
        "                        labeled_logits = torch.gather(\n",
        "                            logits, 0, label_index.expand(label_index.size(0), logits.size(1))\n",
        "                        )\n",
        "                        labels = torch.gather(labels, 0, label_index.view(-1))\n",
        "                        loss_fct = CrossEntropyLoss()\n",
        "                        loss = loss_fct(labeled_logits.view(-1, self.num_labels).float(), labels.view(-1))\n",
        "                    else:\n",
        "                        loss = torch.tensor(0).to(logits)\n",
        "                else:\n",
        "                    log_softmax = nn.LogSoftmax(-1)\n",
        "                    loss = -((log_softmax(logits) * labels).sum(-1)).mean()\n",
        "            elif self.config.problem_type == \"regression\":\n",
        "                loss_fct = MSELoss()\n",
        "                if self.num_labels == 1:\n",
        "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
        "                else:\n",
        "                    loss = loss_fct(logits, labels)\n",
        "            elif self.config.problem_type == \"single_label_classification\":\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            elif self.config.problem_type == \"multi_label_classification\":\n",
        "                loss_fct = BCEWithLogitsLoss()\n",
        "                loss = loss_fct(logits, labels)\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[1:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions\n",
        "        )\n"
      ],
      "metadata": {
        "id": "KGff5RBsXjJg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "model = DebertaForSequenceClassificationV2.from_pretrained(model_name,config=config)\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VyrQhesdX7z",
        "outputId": "c580bcc6-0611-4402-ed5e-173e6d430e71"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForSequenceClassificationV2: ['lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias']\n",
            "- This IS expected if you are initializing DebertaForSequenceClassificationV2 from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaForSequenceClassificationV2 from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaForSequenceClassificationV2 were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.weight', 'classifier.bias', 'pooler.dense.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DebertaForSequenceClassificationV2(\n",
              "  (deberta): DebertaModelV2(\n",
              "    (embeddings): DebertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
              "      (LayerNorm): DebertaLayerNorm()\n",
              "      (dropout): StableDropout()\n",
              "    )\n",
              "    (encoder): DebertaEncoderV2(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x DebertaLayerV2(\n",
              "          (attention): DebertaAttentionV2(\n",
              "            (self): DisentangledSelfAttentionV2(\n",
              "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): DebertaLayerNorm()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): DebertaLayerNorm()\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(1024, 768)\n",
              "    )\n",
              "  )\n",
              "  (pooler): ContextPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): StableDropout()\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): StableDropout()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "# Space module import\n",
        "import en_core_web_md\n",
        "from enum import Enum\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def get_spacy_module():\n",
        "  return en_core_web_md.load()\n",
        "\n",
        "nlp = get_spacy_module()\n",
        "\n",
        "def get_sentence_tokens(s, display = False):\n",
        "  doc = nlp(s)\n",
        "  sentence_tokens = []\n",
        "  if display:\n",
        "    spacy.displacy.render(doc, style=\"dep\", jupyter=True)\n",
        "  for token in doc:\n",
        "    data = {\n",
        "      \"token_id\": token.i,\n",
        "      \"token_text\": token.text,\n",
        "      \"token_connection_ids\": token.head.i,\n",
        "      \"token_left_edge\": token.idx,\n",
        "      \"token_right_edge\": token.idx + len(token.text),\n",
        "      \"token_boundaries\": (token.idx, token.idx + len(token.text)),\n",
        "      \"token_pos_tag\": token.tag_,\n",
        "    }\n",
        "\n",
        "    sentence_tokens.append(data)\n",
        "  return sentence_tokens\n",
        "\n",
        "class TokeniserType(Enum):\n",
        "    ONE_SENTENCE = 1\n",
        "    TWO_SENTENCES = 2\n",
        "\n",
        "class BaseEnrichedTokeniser:\n",
        "  def __init__(self, tokeniser):\n",
        "    self._tokeniser = tokeniser\n",
        "    self.feature_key = None\n",
        "    self.type = TokeniserType.ONE_SENTENCE\n",
        "\n",
        "  def combine_transformer_and_sentence_features(self, transformer_tokens, sentence_features):\n",
        "    for i in range(len(transformer_tokens)):\n",
        "      transformer_tokens[i][self.feature_key] = None\n",
        "      for j in range(len(sentence_features)):\n",
        "        t_boundaries = transformer_tokens[i]['boundaries']\n",
        "        s_boundaries = sentence_features[j]['boundaries']\n",
        "        left = max(t_boundaries[0], s_boundaries[0])\n",
        "        right = min(t_boundaries[1], s_boundaries[1])\n",
        "        if left < right:\n",
        "          transformer_tokens[i][self.feature_key] = sentence_features[j][self.feature_key]\n",
        "\n",
        "      assert(transformer_tokens[i][self.feature_key] is not None)\n",
        "\n",
        "    return transformer_tokens\n",
        "\n",
        "  def get_feature(self, s):\n",
        "    raise Exception(\"Not implemented\")\n",
        "\n",
        "  def enrich_tokens(self, s):\n",
        "    t_tokens = self.get_transformer_sentence_tokens(s)\n",
        "    feature = self.get_feature(s)\n",
        "    combined_features = self.combine_transformer_and_sentence_features(t_tokens, feature)\n",
        "    return combined_features\n",
        "\n",
        "  \"\"\"\n",
        "  Return list of tokens that will be used in model\n",
        "  [('boundaries':(int, int), 'input_id':int, 'index':int]\n",
        "  \"\"\"\n",
        "  def get_transformer_sentence_tokens(self, s, verbose = False):\n",
        "      encoded = self._tokeniser.batch_encode_plus([s], return_offsets_mapping=True, add_special_tokens=False)\n",
        "      split_tokens = []\n",
        "      for i in range(len(encoded['input_ids'][0])):\n",
        "        split_tokens.append(\n",
        "            {\n",
        "                'index': i,\n",
        "                'input_id': encoded['input_ids'][0][i],\n",
        "                'boundaries': encoded['offset_mapping'][0][i],\n",
        "            }\n",
        "        )\n",
        "      return split_tokens\n",
        "\n",
        "  def post_processing(self, v):\n",
        "    return v\n",
        "\n",
        "class PosTagEnrichedTokeniser(BaseEnrichedTokeniser):\n",
        "\n",
        "  def __init__(self, tokeniser):\n",
        "    super().__init__(tokeniser)\n",
        "    self.feature_key = 'pos_tag'\n",
        "\n",
        "  def get_feature(self, s):\n",
        "    \"\"\"\n",
        "    Return list of [('boundaries':(int, int), 'feature':string)]\n",
        "    \"\"\"\n",
        "    all_tokens = get_sentence_tokens(s)\n",
        "    return [{'boundaries':token['token_boundaries'], 'pos_tag': token['token_pos_tag']} for token in all_tokens]\n",
        "\n",
        "\n",
        "class PosTagIdEnrichedTokeniser(BaseEnrichedTokeniser):\n",
        "  def __init__(self, tokeniser):\n",
        "    super().__init__(tokeniser)\n",
        "    self.feature_key = 'pos_tag_ids'\n",
        "    self.pos_tag_to_id_map = PosTagIdEnrichedTokeniser.load_pos_tag_value_to_idx()\n",
        "\n",
        "  @staticmethod\n",
        "  def load_pos_tag_value_to_idx():\n",
        "  # Computed based on test part of MRPC dataset.\n",
        "    return {\n",
        "        '$': 1,\n",
        "        \"''\": 2,\n",
        "        '(': 3,\n",
        "        ')': 4,\n",
        "        ',': 5,\n",
        "        '.': 6,\n",
        "        ':': 7,\n",
        "        'CC': 8,\n",
        "        'CD': 9,\n",
        "        'DT': 10,\n",
        "        'EX': 11,\n",
        "        'FW': 12,\n",
        "        'IN': 13,\n",
        "        'JJ': 14,\n",
        "        'JJR': 15,\n",
        "        'JJS': 16,\n",
        "        'LS': 17,\n",
        "        'MD': 18,\n",
        "        'NA': 19,\n",
        "        'NN': 20,\n",
        "        'NNP': 21,\n",
        "        'NNPS': 22,\n",
        "        'NNS': 23,\n",
        "        'PRP': 24,\n",
        "        'PRP$': 25,\n",
        "        'RB': 26,\n",
        "        'RBR': 27,\n",
        "        'SYM': 28,\n",
        "        'TO': 29,\n",
        "        'UH': 30,\n",
        "        'UNKNOWN': 31,\n",
        "        'VB': 32,\n",
        "        'VBD': 33,\n",
        "        'VBG': 34,\n",
        "        'VBN': 35,\n",
        "        'VBP': 36,\n",
        "        'VBZ': 37,\n",
        "        'WDT': 38,\n",
        "        'WP': 39,\n",
        "        'WP$': 40,\n",
        "        'WRB': 41,\n",
        "        '``': 42\n",
        "      }\n",
        "\n",
        "  def get_feature(self, s):\n",
        "    \"\"\"\n",
        "    Return list of [('boundaries':(int, int), 'feature':string)]\n",
        "    \"\"\"\n",
        "    all_tokens = get_sentence_tokens(s)\n",
        "    def get_id(pos_tag):\n",
        "      if pos_tag in self.pos_tag_to_id_map:\n",
        "        return self.pos_tag_to_id_map[pos_tag]\n",
        "      return self.pos_tag_to_id_map['UNKNOWN']\n",
        "    return [{'boundaries':token['token_boundaries'], self.feature_key: get_id(token['token_pos_tag'])} for token in all_tokens]\n",
        "\n",
        "  def post_processing(self, s1_s2_feature):\n",
        "    token_mapping = self.get_special_token_mapping()\n",
        "    def replace_token_id(token_id, m):\n",
        "      if token_id in m.keys():\n",
        "        return m[token_id]\n",
        "      return token_id\n",
        "    _s1_s2_feature = [replace_token_id(x, token_mapping) for x in s1_s2_feature]\n",
        "    return _s1_s2_feature\n",
        "\n",
        "  def get_special_token_mapping(self):\n",
        "    return {\n",
        "      self._tokeniser.cls_token_id: self.pos_tag_to_id_map['NA'],\n",
        "      self._tokeniser.sep_token_id: self.pos_tag_to_id_map['NA'],\n",
        "    }\n",
        "\n",
        "\n",
        "class AttentionEnhencerDummyEnrichedTokeniser(BaseEnrichedTokeniser):\n",
        "  def __init__(self, tokeniser):\n",
        "    super().__init__(tokeniser)\n",
        "    self.feature_key = 'attention_enhencer_dummy'\n",
        "    self.type = TokeniserType.TWO_SENTENCES\n",
        "\n",
        "  def enrich_tokens(self, s1, s2,  padding, truncation, max_length, _config):\n",
        "    # Dummy matrix will have 1 for all non padding elements.\n",
        "\n",
        "    dummy = self._tokeniser(s1, s2, truncation=truncation, max_length=max_length, padding=padding)\n",
        "\n",
        "    first_padding_0 = dummy['input_ids'].index(self._tokeniser.pad_token_id)\n",
        "    source = torch.full((first_padding_0,first_padding_0), 1.)\n",
        "    pad_distance =  max_length - first_padding_0\n",
        "\n",
        "    result = F.pad(input=source, pad=(0, pad_distance, 0, pad_distance), mode='constant', value=0.)\n",
        "    return result\n",
        "\n",
        "  def get_feature(self, s):\n",
        "    all_tokens = get_sentence_tokens(s)\n",
        "    return [\n",
        "      {\n",
        "        'boundaries':token['token_boundaries'],\n",
        "        'token_connection_ids': token['token_connection_ids'],\n",
        "        'token_id': token['token_id']\n",
        "      } for token in all_tokens\n",
        "    ]\n",
        "\n",
        "\n",
        "class AttentionEnhencerRandEnrichedTokenise(BaseEnrichedTokeniser):\n",
        "  def __init__(self, tokeniser):\n",
        "    super().__init__(tokeniser)\n",
        "    self.feature_key = 'attention_enhencer_rand'\n",
        "    self.type = TokeniserType.TWO_SENTENCES\n",
        "\n",
        "  def enrich_tokens(self, s1, s2,  padding, truncation, max_length, _config):\n",
        "    # Dummy matrix will have 1 for all non padding elements.\n",
        "\n",
        "    dummy = self._tokeniser(s1, s2, truncation=truncation, max_length=max_length, padding=padding)\n",
        "\n",
        "    first_padding_0 = dummy['input_ids'].index(self._tokeniser.pad_token_id)\n",
        "    source = torch.rand((first_padding_0,first_padding_0))\n",
        "    pad_distance =  max_length - first_padding_0\n",
        "\n",
        "    result = F.pad(input=source, pad=(0, pad_distance, 0, pad_distance), mode='constant', value=0.)\n",
        "    return result\n",
        "\n",
        "  def get_feature(self, s):\n",
        "    all_tokens = get_sentence_tokens(s)\n",
        "    return [\n",
        "      {\n",
        "        'boundaries':token['token_boundaries'],\n",
        "        'token_connection_ids': token['token_connection_ids'],\n",
        "        'token_id': token['token_id']\n",
        "      } for token in all_tokens\n",
        "    ]\n",
        "\n",
        "class AttentionEnhencerOneEnrichedTokenise(BaseEnrichedTokeniser):\n",
        "  def __init__(self, tokeniser):\n",
        "    super().__init__(tokeniser)\n",
        "    self.feature_key = 'attention_enhencer'\n",
        "    self.type = TokeniserType.TWO_SENTENCES\n",
        "\n",
        "  def enrich_tokens(self, s1, s2,  padding, truncation, max_length, _config):\n",
        "    # Dummy matrix will have 1 for all elements.\n",
        "    source = torch.full((max_length,max_length), 1.)\n",
        "\n",
        "    # number_of_attention_heads = 12\n",
        "    # source = source[None, :, :].expand([number_of_attention_heads, max_length, max_length])\n",
        "\n",
        "    return source\n",
        "\n",
        "class AttentionEnhencerDependancyTreeEnrichedTokenise(BaseEnrichedTokeniser):\n",
        "  def __init__(self, tokeniser):\n",
        "    super().__init__(tokeniser)\n",
        "    self.feature_key = 'attention_enhencer'\n",
        "    self.type = TokeniserType.TWO_SENTENCES\n",
        "\n",
        "  def enrich_tokens(self, s1, s2,  padding, truncation, max_length, config):\n",
        "    if 'att_dep_tree_pad_value' in config:\n",
        "      pad_value = config['att_dep_tree_pad_value']\n",
        "    else:\n",
        "      pad_value = 0.\n",
        "\n",
        "    data = self._tokeniser(s1, s2, truncation=truncation, max_length=max_length, padding=padding)\n",
        "    first_padding_0 = data['input_ids'].index(self._tokeniser.pad_token_id)\n",
        "    source = torch.full((first_padding_0,first_padding_0), 1.)\n",
        "    pad_distance =  max_length - first_padding_0\n",
        "    base_table = F.pad(input=source, pad=(0, pad_distance, 0, pad_distance), mode='constant', value=pad_value)\n",
        "    # Here we have table\n",
        "    # [1, ...1, 0, ..0]\n",
        "    # [...............]\n",
        "    # [1, ...1, 0, ..0]\n",
        "    # [...............]\n",
        "    # [0, ...0, 0, ..0]\n",
        "\n",
        "    # First sentence start\n",
        "    s1_start_inx = 1\n",
        "    sep_inx = data['input_ids'].index(self._tokeniser.sep_token_id)\n",
        "    s1_end_inx = sep_inx - 1\n",
        "    s2_start_inx = sep_inx + 1\n",
        "    s2_end_inx = first_padding_0 - 2\n",
        "\n",
        "    # print(f\"First start {s1_start_inx} end {s1_end_inx}\")\n",
        "    # print(f\"Second start {s2_start_inx} end {s2_end_inx}\")\n",
        "\n",
        "    # for i in range(s1_end_inx - s1_start_inx + 1):\n",
        "    #   for j in range(s1_end_inx - s1_start_inx + 1):\n",
        "    #     base_table[s1_start_inx + i][s1_start_inx + j] = 2.\n",
        "\n",
        "    # for i in range(s2_end_inx - s2_start_inx + 1):\n",
        "    #   for j in range(s2_end_inx - s2_start_inx + 1):\n",
        "    #     base_table[s2_start_inx + i][s2_start_inx + j] = 3.\n",
        "\n",
        "    s1_tokens = self.get_transformer_sentence_tokens(s1)\n",
        "    s2_tokens = self.get_transformer_sentence_tokens(s2)\n",
        "\n",
        "    s1_feature = self.get_feature(s1)\n",
        "    s2_feature = self.get_feature(s2)\n",
        "\n",
        "    def boundaries_match(transformer_token_boundary, sentence_feature_boundary):\n",
        "      left = max(transformer_token_boundary[0], sentence_feature_boundary[0])\n",
        "      right = min(transformer_token_boundary[1], sentence_feature_boundary[1])\n",
        "      return left < right\n",
        "\n",
        "    def build_token_map(tokens, features):\n",
        "      # Feature token id => [list of token ids]\n",
        "      m = {}\n",
        "      for i in range(len(features)):\n",
        "        m[i] = []\n",
        "        for j in range(len(tokens)):\n",
        "          feature_boundary = features[i]['boundaries']\n",
        "          token_boundary = tokens[j]['boundaries']\n",
        "          if boundaries_match(token_boundary, feature_boundary):\n",
        "            # we need to add pair\n",
        "            m[i].append(j)\n",
        "      return m\n",
        "\n",
        "    val = config['att_dep_tree_value']\n",
        "\n",
        "    def update_base_table(table, tokens, features, max_len, offset):\n",
        "      token_map = build_token_map(tokens, features)\n",
        "      for i in range(len(features)):\n",
        "        feature = features[i]\n",
        "        connected_node_id = feature['token_connection_ids']\n",
        "        feature_connected = features[connected_node_id]\n",
        "        tokens = token_map[i]\n",
        "        connected_tokens = token_map[connected_node_id]\n",
        "        for _x in tokens:\n",
        "          for _y in connected_tokens:\n",
        "            if _x < max_len and _y < max_len:\n",
        "              table[offset + _x][offset + _y] = val\n",
        "              table[offset + _y][offset + _x] = val\n",
        "      return table\n",
        "\n",
        "    base_table = update_base_table(base_table, s1_tokens, s1_feature, s1_end_inx - s1_start_inx + 1, s1_start_inx)\n",
        "    base_table = update_base_table(base_table, s2_tokens, s2_feature, s2_end_inx - s2_start_inx + 1, s2_start_inx)\n",
        "\n",
        "    # number_of_attention_heads = 12\n",
        "    # base_table = base_table[None, :, :].expand([number_of_attention_heads, max_length, max_length])\n",
        "    return base_table\n",
        "\n",
        "  def get_feature(self, s):\n",
        "    all_tokens = get_sentence_tokens(s)\n",
        "    return [\n",
        "      {\n",
        "        'boundaries':token['token_boundaries'],\n",
        "        'token_connection_ids': token['token_connection_ids'],\n",
        "        'token_id': token['token_id']\n",
        "      } for token in all_tokens\n",
        "    ]\n",
        "\n",
        "class FinalTokeniser:\n",
        "  def __init__(self, tokeniser, config):\n",
        "    self._tokeniser = tokeniser\n",
        "    self._config = config\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def _prepare_for_model(tokeniser, s1, s2, padding, truncation, max_length):\n",
        "    return tokeniser.prepare_for_model(\n",
        "      s1,\n",
        "      s2,\n",
        "      padding=padding,\n",
        "      truncation=truncation,\n",
        "      max_length=max_length,\n",
        "    )['input_ids']\n",
        "\n",
        "  def apply_tokenisers(self, s1, s2, tokeniser_list, padding, truncation, max_length):\n",
        "    # Get base data first: input ids, token_ids, attention_mask\n",
        "    encoded_base = self._tokeniser.batch_encode_plus([s1, s2], return_offsets_mapping=True, add_special_tokens=False)\n",
        "    s1_input_ids = encoded_base['input_ids'][0]\n",
        "    s2_input_ids = encoded_base['input_ids'][1]\n",
        "\n",
        "    _prepare_for_model = FinalTokeniser._prepare_for_model\n",
        "\n",
        "    s1_s2_input_ids = _prepare_for_model(self._tokeniser, s1_input_ids, s2_input_ids, padding, truncation, max_length)\n",
        "\n",
        "    data = {\n",
        "      'input_ids': s1_s2_input_ids,\n",
        "    }\n",
        "\n",
        "    for tokeniser in tokeniser_list:\n",
        "      if tokeniser.type == TokeniserType.ONE_SENTENCE:\n",
        "        enriched_data_s1 = tokeniser.enrich_tokens(s1)\n",
        "        enriched_data_s2 = tokeniser.enrich_tokens(s2)\n",
        "\n",
        "        _s1_input_ids = [x['input_id'] for x in enriched_data_s1]\n",
        "        _s2_input_ids = [x['input_id'] for x in enriched_data_s2]\n",
        "\n",
        "        assert(s1_input_ids == _s1_input_ids)\n",
        "        assert(s2_input_ids == _s2_input_ids)\n",
        "\n",
        "        s1_feature = [x[tokeniser.feature_key] for x in enriched_data_s1]\n",
        "        s2_feature = [x[tokeniser.feature_key] for x in enriched_data_s2]\n",
        "\n",
        "        s1_s2_feature = _prepare_for_model(self._tokeniser, s1_feature, s2_feature,  padding, truncation, max_length)\n",
        "      else:\n",
        "        s1_s2_feature = tokeniser.enrich_tokens(s1, s2,  padding, truncation, max_length, self._config)\n",
        "\n",
        "      s1_s2_feature = tokeniser.post_processing(s1_s2_feature)\n",
        "\n",
        "      data[tokeniser.feature_key] = s1_s2_feature\n",
        "\n",
        "\n",
        "    return data\n",
        "\n",
        "  def tokenise_everything(self, s1, s2, padding, truncation, max_length):\n",
        "    if 'tokeniser_list' in self._config:\n",
        "      tokeniser_list = self._config['tokeniser_list']\n",
        "    else:\n",
        "      tokeniser_list = ['dep']\n",
        "\n",
        "    list_of_tokenisers = []\n",
        "    if 'pos' in tokeniser_list:\n",
        "      pos_tag_id_tokeniser = PosTagIdEnrichedTokeniser(self._tokeniser)\n",
        "      list_of_tokenisers.append(pos_tag_id_tokeniser)\n",
        "\n",
        "    if 'attention_dummy' in tokeniser_list:\n",
        "      attention_dummy_tokeniser = AttentionEnhencerDummyEnrichedTokeniser(self._tokeniser)\n",
        "      list_of_tokenisers.append(attention_dummy_tokeniser)\n",
        "\n",
        "    if 'attention_dep' in tokeniser_list:\n",
        "      attention_tokeniser_dep = AttentionEnhencerDependancyTreeEnrichedTokenise(self._tokeniser)\n",
        "      list_of_tokenisers.append(attention_tokeniser_dep)\n",
        "\n",
        "    if 'attention_one' in tokeniser_list:\n",
        "      attention_tokeniser_one = AttentionEnhencerOneEnrichedTokenise(self._tokeniser)\n",
        "      list_of_tokenisers.append(attention_tokeniser_one)\n",
        "\n",
        "    AttentionEnhencerDependancyTreeEnrichedTokenise\n",
        "    return self.apply_tokenisers(\n",
        "      s1,\n",
        "      s2,\n",
        "      list_of_tokenisers,\n",
        "      padding,\n",
        "      truncation,\n",
        "      max_length\n",
        "    )\n",
        "\n",
        "def preprocess_dataset_final(examples, tokenizer, truncation, max_length, padding, config):\n",
        "  basic_tokenizer_data = tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=truncation, max_length=max_length, padding=padding)\n",
        "  final_tokeniser = FinalTokeniser(tokeniser=tokenizer, config=config)\n",
        "  enriched_data = final_tokeniser.tokenise_everything(examples[\"sentence1\"], examples[\"sentence2\"], truncation=truncation, max_length=max_length, padding=padding)\n",
        "  assert(basic_tokenizer_data['input_ids'] == enriched_data['input_ids'])\n",
        "  for feature, value in enriched_data.items():\n",
        "    basic_tokenizer_data[feature] = value\n",
        "  return basic_tokenizer_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd8lJ5jDt-z0",
        "outputId": "3edd7b3e-0c7a-445d-c211-2273fb12510e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = load_dataset(\"glue\", 'mrpc', split=f\"train{DATASET_PART}\")\n",
        "dataset_eval = load_dataset(\"glue\", 'mrpc', split=f\"validation{DATASET_PART}\")\n",
        "dataset_test = load_dataset(\"glue\", 'mrpc', split=f\"test{DATASET_PART}\")\n",
        "\n",
        "config = {\n",
        "    'att_dep_tree_value': 0.8,\n",
        "    'att_dep_tree_pad_value': 0.,\n",
        "    'tokeniser_list': ['attention_dep'],\n",
        "}\n",
        "\n",
        "preprocess_dataset_with_full_v2 = partial(\n",
        "    preprocess_dataset_final,\n",
        "    tokenizer=model_tokenizer,\n",
        "    truncation=TRUNCATION,\n",
        "    max_length=MAX_LEN,\n",
        "    padding=PADDING,\n",
        "    config=config,\n",
        "  )\n",
        "\n",
        "collator = DataCollatorWithPadding(model_tokenizer)\n",
        "\n",
        "def prepare_dataloader(dataset, collator):\n",
        "  dataset = dataset.map(preprocess_dataset_with_full_v2, batched=False)\n",
        "  dataset = dataset.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\n",
        "  dataset = dataset.rename_column(\"label\", \"labels\")\n",
        "  dataset.set_format(\"torch\")\n",
        "  dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn=collator)\n",
        "  return dataloader\n",
        "\n",
        "\n",
        "train_dataloader = prepare_dataloader(dataset_train, collator)\n",
        "eval_dataloader = prepare_dataloader(dataset_eval, collator)\n",
        "test_dataloader = prepare_dataloader(dataset_test, collator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "e3bf529114244e00a642db767eacdcc6",
            "f761415994a84df5bcbce155329a383b",
            "d83d9326bdf64d0b834916234e4a5de3",
            "ed2ee18a2d4a441f9ce7984cbc09ebff",
            "a56e82a22b714468bfc89148c3e2b4e7",
            "4683ed90c3c04287ba4667913c6a664f",
            "e6fc4b72706449ffa2c54e68a5b1bd85",
            "b67f3472c086401588afb34730a9ba25",
            "94eb9a7153af4295a0378bf6e70e75ca",
            "2849e8f2841c49a1af964045956b3a70",
            "3c9f305cf875429390b6f6f3016e1b1a",
            "deda32776a354094ab0f0b5f369dbfc1",
            "0599f81a36ac412aa94b466bc6d772ce",
            "a33686dfe72e4d8abafe0101a461c608",
            "0e4e92a860ba4658a07f2dc4bf2575b6",
            "690867ed54d0431ab3ef89b587db2353",
            "529fa1466faf4642a1dbf5a948a2cdf3",
            "426c71faf9a244df9965258ca85aaddf",
            "16599f70c76f4d9ea40d44dae2a989f0",
            "ab98eeafa7c14ecbb455bb6680068c1b",
            "44866e7581314b97821140d8da1a2d3a",
            "5548eedb6f534f4b9299dd1d0b76b407",
            "a32648ffa9204b908a959c8bb8341ade",
            "dd8916407dff47818f80d9d6d1e7dfd3",
            "531affd96b454e0ba5535a97cf13a5a4",
            "2d39afa2ee344846b7c2683f00b67c6e",
            "e66ee939064b468382b066f010cb153a",
            "310762e02ce74a3586cc06183c05fbad",
            "f799499ebb7b4407819f5599dbb798f7",
            "f5443cad6d6144ce85b3c599914b8f1e",
            "6159353d1d9b48d0aa6219ecce6bc308",
            "1eee788f28da45fa8ed2c9516bc2f95a",
            "887e519bc2744ad4a837de29504c27cd"
          ]
        },
        "id": "9VyY6A5ViFln",
        "outputId": "d30ecfe0-153e-4484-b1f8-d645389a1a48"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dill/_dill.py:412: PicklingWarning: Cannot locate reference to <enum 'TokeniserType'>.\n",
            "  StockPickler.save(self, obj, save_persistent_id)\n",
            "/usr/local/lib/python3.10/dist-packages/dill/_dill.py:412: PicklingWarning: Cannot pickle <enum 'TokeniserType'>: __main__.TokeniserType has recursive self-references that trigger a RecursionError.\n",
            "  StockPickler.save(self, obj, save_persistent_id)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3bf529114244e00a642db767eacdcc6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "deda32776a354094ab0f0b5f369dbfc1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a32648ffa9204b908a959c8bb8341ade"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for b in train_dataloader:\n",
        "  print(b.keys())\n",
        "  break\n",
        "for b in eval_dataloader:\n",
        "  print(b.keys())\n",
        "  break\n",
        "for b in test_dataloader:\n",
        "  print(b.keys())\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJgOeNznYN2D",
        "outputId": "7a263b78-4cee-43de-b315-a81ec957bfeb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['labels', 'input_ids', 'token_type_ids', 'attention_mask', 'attention_enhencer'])\n",
            "dict_keys(['labels', 'input_ids', 'token_type_ids', 'attention_mask', 'attention_enhencer'])\n",
            "dict_keys(['labels', 'input_ids', 'token_type_ids', 'attention_mask', 'attention_enhencer'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBLt54T69QH1",
        "outputId": "bd79ed6a-7a1f-4359-eb1b-83a0d653c4ff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'att_dep_tree_value': 0.8,\n",
              " 'att_dep_tree_pad_value': 0.0,\n",
              " 'tokeniser_list': ['attention_dep']}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "optimizer = AdamW(model.parameters(), lr=LR)\n",
        "\n",
        "num_training_steps = NUM_TRAIN_EPOCHS * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")"
      ],
      "metadata": {
        "id": "UbHm-r_NfqlA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_eval_test(model, optimizer, lr_scheduler,  train_dataloader, eval_dataloader,test_dataloader,  num_train_epochs, num_training_steps, device):\n",
        "  progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "  def prepare_batch(b):\n",
        "    (B, L, L) = b['attention_enhencer'].size()\n",
        "    number_of_attention_heads = 12\n",
        "    b['attention_enhencer'] = b['attention_enhencer'][:, None, :, :].expand([B, number_of_attention_heads, L, L])\n",
        "    return b\n",
        "  for epoch in range(num_train_epochs):\n",
        "      print(f\"Epoch {epoch}\")\n",
        "      model.train()\n",
        "      for batch in train_dataloader:\n",
        "          batch = prepare_batch(batch)\n",
        "          batch = {k: v.to(device) for k, v in batch.items()}\n",
        "          outputs = model(**batch)\n",
        "          loss = outputs.loss\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "          lr_scheduler.step()\n",
        "          optimizer.zero_grad()\n",
        "          progress_bar.update(1)\n",
        "\n",
        "      accuracy_metric = evaluate.load(\"accuracy\")\n",
        "      f1_metric = evaluate.load(\"f1\")\n",
        "      model.eval()\n",
        "      for batch in eval_dataloader:\n",
        "          batch = prepare_batch(batch)\n",
        "          batch = {k: v.to(device) for k, v in batch.items()}\n",
        "          with torch.no_grad():\n",
        "              outputs = model(**batch)\n",
        "\n",
        "          logits = outputs.logits\n",
        "          predictions = torch.argmax(logits, dim=-1)\n",
        "          accuracy_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "          f1_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "      acc = accuracy_metric.compute()\n",
        "      f1 = f1_metric.compute()\n",
        "      print(f\"Eval accuracy {acc['accuracy']:.4f}\")\n",
        "      print(f\"Eval F1 {f1['f1']:.4f}\")\n",
        "\n",
        "\n",
        "      test_accuracy_metric = evaluate.load(\"accuracy\")\n",
        "      test_f1_metric = evaluate.load(\"f1\")\n",
        "      model.eval()\n",
        "      for batch in test_dataloader:\n",
        "          batch = prepare_batch(batch)\n",
        "          batch = {k: v.to(device) for k, v in batch.items()}\n",
        "          with torch.no_grad():\n",
        "              outputs = model(**batch)\n",
        "\n",
        "          logits = outputs.logits\n",
        "          predictions = torch.argmax(logits, dim=-1)\n",
        "          test_accuracy_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "          test_f1_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "      acc = test_accuracy_metric.compute()\n",
        "      f1 = test_f1_metric.compute()\n",
        "      print(f\"Test accuracy {acc['accuracy']:.4f}\")\n",
        "      print(f\"Test F1 {f1['f1']:.4f}\")\n",
        "\n",
        "\n",
        "train_eval_test(\n",
        "  model = model,\n",
        "  optimizer = optimizer,\n",
        "  lr_scheduler = lr_scheduler,\n",
        "  train_dataloader = train_dataloader,\n",
        "  eval_dataloader = eval_dataloader,\n",
        "  test_dataloader = test_dataloader,\n",
        "  num_train_epochs = NUM_TRAIN_EPOCHS,\n",
        "  num_training_steps = num_training_steps,\n",
        "  device = device,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917,
          "referenced_widgets": [
            "57f2783ce67642bda5534cd8de9363ec",
            "a5f8238319b54d9b9cd54c6024700386",
            "c229efd7f6df45c5941a3d3a86dac224",
            "bd60c6cb064e4dd3b8d10c2ec912f84f",
            "f8c550d9175c4b33bc8898080b8ce665",
            "4dbf4cf75ac94664a1494fd42122607c",
            "36e3bfe1a83c43ffb7671383ff44c4cb",
            "9af8cb66c6c2490ea5cc947eff9f3d04",
            "be02eba9b71c440e94b23f8329370d2a",
            "dc7b800aa5614864a236df1f510c6bff",
            "1ccb3a623fd247ac9a7d5cd3698dc8ed"
          ]
        },
        "id": "78w9MeOagAja",
        "outputId": "307cb0ac-324c-4254-ab0c-96a9c1164192"
      },
      "execution_count": 15,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57f2783ce67642bda5534cd8de9363ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4590 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "Eval accuracy 0.8848\n",
            "Eval F1 0.9191\n",
            "Test accuracy 0.8516\n",
            "Test F1 0.8947\n",
            "Epoch 1\n",
            "Eval accuracy 0.8873\n",
            "Eval F1 0.9207\n",
            "Test accuracy 0.8603\n",
            "Test F1 0.9000\n",
            "Epoch 2\n",
            "Eval accuracy 0.9020\n",
            "Eval F1 0.9293\n",
            "Test accuracy 0.8754\n",
            "Test F1 0.9075\n",
            "Epoch 3\n",
            "Eval accuracy 0.9044\n",
            "Eval F1 0.9315\n",
            "Test accuracy 0.8643\n",
            "Test F1 0.9019\n",
            "Epoch 4\n",
            "Eval accuracy 0.8946\n",
            "Eval F1 0.9247\n",
            "Test accuracy 0.8701\n",
            "Test F1 0.9064\n",
            "Epoch 5\n",
            "Eval accuracy 0.8848\n",
            "Eval F1 0.9156\n",
            "Test accuracy 0.8771\n",
            "Test F1 0.9076\n",
            "Epoch 6\n",
            "Eval accuracy 0.8922\n",
            "Eval F1 0.9211\n",
            "Test accuracy 0.8748\n",
            "Test F1 0.9064\n",
            "Epoch 7\n",
            "Eval accuracy 0.8995\n",
            "Eval F1 0.9277\n",
            "Test accuracy 0.8777\n",
            "Test F1 0.9106\n",
            "Epoch 8\n",
            "Eval accuracy 0.8995\n",
            "Eval F1 0.9277\n",
            "Test accuracy 0.8852\n",
            "Test F1 0.9157\n",
            "Epoch 9\n",
            "Eval accuracy 0.8995\n",
            "Eval F1 0.9279\n",
            "Test accuracy 0.8823\n",
            "Test F1 0.9146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import login\n",
        "\n",
        "# huggingface_token = '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'\n",
        "\n",
        "# login(token=huggingface_token)\n",
        "# m = model_name.split('/')[-1]\n",
        "# model.push_to_hub(f\"VitaliiVrublevskyi/mrpc_{m}_base_dummy_attention\")"
      ],
      "metadata": {
        "id": "1eVp8ufH5rou"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy [1, ...1, 000]\n",
        "# V100\n",
        "# MAX_LEN = 256\n",
        "# BATCH_SIZE = 8\n",
        "# SEED = 42\n",
        "# Epoch 0\n",
        "# Eval accuracy 0.8848\n",
        "# Eval F1 0.9188\n",
        "# Test accuracy 0.8736\n",
        "# Test F1 0.9082\n",
        "# Epoch 1\n",
        "# Eval accuracy 0.8971\n",
        "# Eval F1 0.9261\n",
        "# Test accuracy 0.8875\n",
        "# Test F1 0.9171"
      ],
      "metadata": {
        "id": "p5MSz3xA6ePg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rand [r, ...r, 000]\n",
        "# V100\n",
        "# MAX_LEN = 256\n",
        "# BATCH_SIZE = 8\n",
        "# SEED = 42\n",
        "# Epoch 0\n",
        "# Eval accuracy 0.7010\n",
        "# Eval F1 0.8146\n",
        "# Test accuracy 0.6846\n",
        "# Test F1 0.7993\n",
        "# Epoch 1\n",
        "# Eval accuracy 0.6838\n",
        "# Eval F1 0.8122\n",
        "# Test accuracy 0.6649\n",
        "# Test F1 0.7987"
      ],
      "metadata": {
        "id": "K5e3lgqQLO8q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dep Tree 1.2 [1, ...1, 000]\n",
        "# V100\n",
        "# MAX_LEN = 256\n",
        "# BATCH_SIZE = 8\n",
        "# SEED = 42\n",
        "# Epoch 0\n",
        "# Eval accuracy 0.8652\n",
        "# Eval F1 0.9073\n",
        "# Test accuracy 0.8435\n",
        "# Test F1 0.8914\n",
        "# Epoch 1\n",
        "# Eval accuracy 0.8922\n",
        "# Eval F1 0.9239\n",
        "# Test accuracy 0.8788\n",
        "# Test F1 0.9119"
      ],
      "metadata": {
        "id": "XDLpfCL4eOvc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dep Tree 0.8 [1, ...1, 000]\n",
        "# V100\n",
        "# MAX_LEN = 256\n",
        "# BATCH_SIZE = 8\n",
        "# SEED = 42\n",
        "# Epoch 0\n",
        "# Eval accuracy 0.8407\n",
        "# Eval F1 0.8896\n",
        "# Test accuracy 0.8174\n",
        "# Test F1 0.8717\n",
        "# Epoch 1\n",
        "# Eval accuracy 0.8603\n",
        "# Eval F1 0.9016\n",
        "# Test accuracy 0.8493\n",
        "# Test F1 0.8906"
      ],
      "metadata": {
        "id": "YYkG0R82j_NP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy [1, ...1, 000]\n",
        "# V100\n",
        "# MAX_LEN = 256\n",
        "# BATCH_SIZE = 8\n",
        "# SEED = 42\n",
        "# Epoch 0\n",
        "# Eval accuracy 0.8750\n",
        "# Eval F1 0.9125\n",
        "# Test accuracy 0.8365\n",
        "# Test F1 0.8849\n",
        "# Epoch 1\n",
        "# Eval accuracy 0.8873\n",
        "# Eval F1 0.9179\n",
        "# Test accuracy 0.8713\n",
        "# Test F1 0.9040\n",
        "# Epoch 2\n",
        "# Eval accuracy 0.8922\n",
        "# Eval F1 0.9241\n",
        "# Test accuracy 0.8696\n",
        "# Test F1 0.9067\n",
        "# Epoch 3\n",
        "# Eval accuracy 0.8995\n",
        "# Eval F1 0.9287\n",
        "# Test accuracy 0.8794\n",
        "# Test F1 0.9116\n",
        "# Epoch 4\n",
        "# Eval accuracy 0.8897\n",
        "# Eval F1 0.9220\n",
        "# Test accuracy 0.8777\n",
        "# Test F1 0.9099\n",
        "# CommitInfo(commit_url='https://huggingface.co/VitaliiVrublevskyi/mrpc_deberta-base_base_dummy_attention/commit/59064cbb6a87216ca69584729002ab6fa5c2b139', commit_message='Upload DebertaForSequenceClassificationV2', commit_description='', oid='59064cbb6a87216ca69584729002ab6fa5c2b139', pr_url=None, pr_revision=None, pr_num=None)"
      ],
      "metadata": {
        "id": "5vrn8GW664j1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dep Tree 1 [1, ...1, 000]\n",
        "# V100\n",
        "# MAX_LEN = 256\n",
        "# BATCH_SIZE = 8\n",
        "# SEED = 42\n",
        "# Epoch 0\n",
        "# Epoch 0\n",
        "# Eval accuracy 0.7010\n",
        "# Eval F1 0.8201\n",
        "# Test accuracy 0.6951\n",
        "# Test F1 0.8124\n",
        "# Epoch 1\n",
        "# Eval accuracy 0.6838\n",
        "# Eval F1 0.8122\n",
        "# Test accuracy 0.6649\n",
        "# Test F1 0.7987"
      ],
      "metadata": {
        "id": "KJTfrIE7Meg3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline, empty enhancer\n",
        "# MAX_LEN = 256\n",
        "# BATCH_SIZE = 8\n",
        "# SEED = 42\n",
        "# NUM_TRAIN_EPOCHS = 10\n",
        "\n",
        "# Epoch 0\n",
        "# Eval accuracy 0.8333\n",
        "# Eval F1 0.8885\n",
        "# Test accuracy 0.8081\n",
        "# Test F1 0.8713\n",
        "# Epoch 1\n",
        "# Eval accuracy 0.8995\n",
        "# Eval F1 0.9287\n",
        "# Test accuracy 0.8713\n",
        "# Test F1 0.9071\n",
        "# Epoch 2\n",
        "# Eval accuracy 0.8922\n",
        "# Eval F1 0.9225\n",
        "# Test accuracy 0.8696\n",
        "# Test F1 0.9041\n",
        "# Epoch 3\n",
        "# Eval accuracy 0.9044\n",
        "# Eval F1 0.9319\n",
        "# Test accuracy 0.8730\n",
        "# Test F1 0.9071\n",
        "# Epoch 4\n",
        "# Eval accuracy 0.8873\n",
        "# Eval F1 0.9199\n",
        "# Test accuracy 0.8754\n",
        "# Test F1 0.9098\n",
        "# Epoch 5\n",
        "# Eval accuracy 0.8873\n",
        "# Eval F1 0.9190\n",
        "# Test accuracy 0.8852  <------------------\n",
        "# Test F1 0.9154 <------------------\n",
        "# Epoch 6\n",
        "# Eval accuracy 0.8873\n",
        "# Eval F1 0.9201\n",
        "# Test accuracy 0.8748\n",
        "# Test F1 0.9097\n",
        "# Epoch 7\n",
        "# Eval accuracy 0.8603\n",
        "# Eval F1 0.9052\n",
        "# Test accuracy 0.8330\n",
        "# Test F1 0.8850\n",
        "# Epoch 8\n",
        "# Eval accuracy 0.9044\n",
        "# Eval F1 0.9322\n",
        "# Test accuracy 0.8719\n",
        "# Test F1 0.9072\n",
        "# Epoch 9\n",
        "# Eval accuracy 0.9020\n",
        "# Eval F1 0.9298\n",
        "# Test accuracy 0.8736\n",
        "# Test F1 0.9072"
      ],
      "metadata": {
        "id": "fH0qHkDarfVT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dep Enhancer, 1.2 increase, 0 pad\n",
        "# MAX_LEN = 256\n",
        "# BATCH_SIZE = 8\n",
        "# SEED = 42\n",
        "# NUM_TRAIN_EPOCHS = 10\n",
        "# Epoch 0\n",
        "# Eval accuracy 0.6740\n",
        "# Eval F1 0.7899\n",
        "# Test accuracy 0.6910\n",
        "# Test F1 0.7983\n",
        "# Epoch 1\n",
        "# Eval accuracy 0.7010\n",
        "# Eval F1 0.8201\n",
        "# Test accuracy 0.6916\n",
        "# Test F1 0.8104\n",
        "# Epoch 2\n",
        "# Eval accuracy 0.8627\n",
        "# Eval F1 0.9076\n",
        "# Test accuracy 0.8267\n",
        "# Test F1 0.8808\n",
        "# Epoch 3\n",
        "# Eval accuracy 0.8897\n",
        "# Eval F1 0.9220\n",
        "# Test accuracy 0.8545\n",
        "# Test F1 0.8940\n",
        "# Epoch 4\n",
        "# Eval accuracy 0.8701\n",
        "# Eval F1 0.9103\n",
        "# Test accuracy 0.8452\n",
        "# Test F1 0.8907\n",
        "# Epoch 5\n",
        "# Eval accuracy 0.8775\n",
        "# Eval F1 0.9161\n",
        "# Test accuracy 0.8533\n",
        "# Test F1 0.8970\n",
        "# Epoch 6\n",
        "# Eval accuracy 0.8775\n",
        "# Eval F1 0.9161\n",
        "# Test accuracy 0.8516\n",
        "# Test F1 0.8959\n",
        "# Epoch 7\n",
        "# Eval accuracy 0.8873\n",
        "# Eval F1 0.9201\n",
        "# Test accuracy 0.8701\n",
        "# Test F1 0.9047\n",
        "# Epoch 8\n",
        "# Eval accuracy 0.8897\n",
        "# Eval F1 0.9220\n",
        "# Test accuracy 0.8736 <--------------\n",
        "# Test F1 0.9075 <--------------\n",
        "# Epoch 9\n",
        "# Eval accuracy 0.8971\n",
        "# Eval F1 0.9281\n",
        "# Test accuracy 0.8667\n",
        "# Test F1 0.9039"
      ],
      "metadata": {
        "id": "b3FxjLCdMzKA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dep Enhancer, 1.1 increase, 0 pad\n",
        "# MAX_LEN = 256\n",
        "# BATCH_SIZE = 8\n",
        "# SEED = 42\n",
        "# NUM_TRAIN_EPOCHS = 10\n",
        "# Epoch 0\n",
        "# Eval accuracy 0.6838\n",
        "# Eval F1 0.8122\n",
        "# Test accuracy 0.6649\n",
        "# Test F1 0.7987\n",
        "# Epoch 1\n",
        "# Eval accuracy 0.6961\n",
        "# Eval F1 0.8182\n",
        "# Test accuracy 0.6829\n",
        "# Test F1 0.8072\n",
        "# Epoch 2\n",
        "# Eval accuracy 0.8750\n",
        "# Eval F1 0.9140\n",
        "# Test accuracy 0.8487\n",
        "# Test F1 0.8933\n",
        "# Epoch 3\n",
        "# Eval accuracy 0.8725\n",
        "# Eval F1 0.9044\n",
        "# Test accuracy 0.8475\n",
        "# Test F1 0.8818\n",
        "# Epoch 4\n",
        "# Eval accuracy 0.8627\n",
        "# Eval F1 0.9060\n",
        "# Test accuracy 0.8464\n",
        "# Test F1 0.8928\n",
        "# Epoch 5\n",
        "# Eval accuracy 0.8848\n",
        "# Eval F1 0.9180\n",
        "# Test accuracy 0.8684\n",
        "# Test F1 0.9039\n",
        "# Epoch 6\n",
        "# Eval accuracy 0.8750\n",
        "# Eval F1 0.9113\n",
        "# Test accuracy 0.8678\n",
        "# Test F1 0.9029\n",
        "# Epoch 7\n",
        "# Eval accuracy 0.8799\n",
        "# Eval F1 0.9139\n",
        "# Test accuracy 0.8707\n",
        "# Test F1 0.9032\n",
        "# Epoch 8\n",
        "# Eval accuracy 0.8897\n",
        "# Eval F1 0.9212\n",
        "# Test accuracy 0.8771   <--------------\n",
        "# Test F1 0.9089         <--------------\n",
        "# Epoch 9\n",
        "# Eval accuracy 0.8824\n",
        "# Eval F1 0.9172\n",
        "# Test accuracy 0.8719\n",
        "# Test F1 0.9062"
      ],
      "metadata": {
        "id": "wrs5jFe5mvZY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dep Enhancer, 0.9 increase, 0 pad\n",
        "# MAX_LEN = 256\n",
        "# BATCH_SIZE = 8\n",
        "# SEED = 42\n",
        "# NUM_TRAIN_EPOCHS = 10\n",
        "# Epoch 0\n",
        "# Eval accuracy 0.8701\n",
        "# Eval F1 0.9115\n",
        "# Test accuracy 0.8359\n",
        "# Test F1 0.8874\n",
        "# Epoch 1\n",
        "# Eval accuracy 0.8873\n",
        "# Eval F1 0.9210\n",
        "# Test accuracy 0.8742\n",
        "# Test F1 0.9097\n",
        "# Epoch 2\n",
        "# Eval accuracy 0.8824\n",
        "# Eval F1 0.9134\n",
        "# Test accuracy 0.8835\n",
        "# Test F1 0.9127\n",
        "# Epoch 3\n",
        "# Eval accuracy 0.8848\n",
        "# Eval F1 0.9180\n",
        "# Test accuracy 0.8730\n",
        "# Test F1 0.9081\n",
        "# Epoch 4\n",
        "# Eval accuracy 0.9020\n",
        "# Eval F1 0.9306\n",
        "# Test accuracy 0.8794\n",
        "# Test F1 0.9116\n",
        "# Epoch 5\n",
        "# Eval accuracy 0.9167\n",
        "# Eval F1 0.9401\n",
        "# Test accuracy 0.8846    <--------------\n",
        "# Test F1 0.9148          <--------------\n",
        "# Epoch 6\n",
        "# Eval accuracy 0.8995\n",
        "# Eval F1 0.9292\n",
        "# Test accuracy 0.8788\n",
        "# Test F1 0.9130\n",
        "# Epoch 7\n",
        "# Eval accuracy 0.9020\n",
        "# Eval F1 0.9306\n",
        "# Test accuracy 0.8800\n",
        "# Test F1 0.9130\n",
        "# Epoch 8\n",
        "# Eval accuracy 0.9044\n",
        "# Eval F1 0.9319\n",
        "# Test accuracy 0.8817\n",
        "# Test F1 0.9139\n",
        "# Epoch 9\n",
        "# Eval accuracy 0.9044\n",
        "# Eval F1 0.9319\n",
        "# Test accuracy 0.8817\n",
        "# Test F1 0.9141"
      ],
      "metadata": {
        "id": "WpvnQeok8rUf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dep Enhancer, 0.8 increase, 0 pad\n",
        "# MAX_LEN = 256\n",
        "# BATCH_SIZE = 8\n",
        "# SEED = 42\n",
        "# NUM_TRAIN_EPOCHS = 10\n",
        "# Epoch 0\n",
        "# Eval accuracy 0.8848\n",
        "# Eval F1 0.9191\n",
        "# Test accuracy 0.8516\n",
        "# Test F1 0.8947\n",
        "# Epoch 1\n",
        "# Eval accuracy 0.8873\n",
        "# Eval F1 0.9207\n",
        "# Test accuracy 0.8603\n",
        "# Test F1 0.9000\n",
        "# Epoch 2\n",
        "# Eval accuracy 0.9020\n",
        "# Eval F1 0.9293\n",
        "# Test accuracy 0.8754\n",
        "# Test F1 0.9075\n",
        "# Epoch 3\n",
        "# Eval accuracy 0.9044\n",
        "# Eval F1 0.9315\n",
        "# Test accuracy 0.8643\n",
        "# Test F1 0.9019\n",
        "# Epoch 4\n",
        "# Eval accuracy 0.8946\n",
        "# Eval F1 0.9247\n",
        "# Test accuracy 0.8701\n",
        "# Test F1 0.9064\n",
        "# Epoch 5\n",
        "# Eval accuracy 0.8848\n",
        "# Eval F1 0.9156\n",
        "# Test accuracy 0.8771\n",
        "# Test F1 0.9076\n",
        "# Epoch 6\n",
        "# Eval accuracy 0.8922\n",
        "# Eval F1 0.9211\n",
        "# Test accuracy 0.8748\n",
        "# Test F1 0.9064\n",
        "# Epoch 7\n",
        "# Eval accuracy 0.8995\n",
        "# Eval F1 0.9277\n",
        "# Test accuracy 0.8777\n",
        "# Test F1 0.9106\n",
        "# Epoch 8\n",
        "# Eval accuracy 0.8995\n",
        "# Eval F1 0.9277\n",
        "# Test accuracy 0.8852\n",
        "# Test F1 0.9157\n",
        "# Epoch 9\n",
        "# Eval accuracy 0.8995\n",
        "# Eval F1 0.9279\n",
        "# Test accuracy 0.8823\n",
        "# Test F1 0.9146"
      ],
      "metadata": {
        "id": "M-dod-3cR6U9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}